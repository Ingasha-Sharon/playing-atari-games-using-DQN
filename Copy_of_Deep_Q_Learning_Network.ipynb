{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ingasha-Sharon/playing-atari-games-using-DQN/blob/main/Copy_of_Deep_Q_Learning_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "aCUUlrqKThkt"
      },
      "cell_type": "markdown",
      "source": [
        "# Playing Atari Games with DQN\n",
        "\n",
        "---\n",
        "\n",
        "## From Q-table to Q-network\n",
        "\n",
        "Last time, we learned about Q-Learning: an algorithm which produces a Q-table that an agent uses to find the best action to take given a state. The Q-table as a “cheat-sheet” helps us to find the maximum expected future reward of an action, given a current state. This was a good strategy — however, this is not scalable. As we see, producing and updating a Q-table can become ineffective in big state space environments.\n",
        "\n",
        "Today, we’ll create a Deep Q Neural Network. Instead of using a Q-table, we’ll implement a Neural Network that takes a state and approximates Q-values for each action based on that state.\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/table_vs_nn.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784358&Signature=GVurCrQRQzuycfpyE4eH0WxvmDyW3dnwlsjaaFGy0GhjoK2g5zId35gqs6BvvooMNw0C1f0vd85CAgD9jtNmFZTjRkGOWTHY6Fz2iMppIjvQrDoAyUbTXLT9iLXPbyuq6u9llIFUEkBsbHFoEf4lllaeAn16r%2FzwuPfLlfTvyh7Q1CcZvy%2B1ItkXpmXMS9FYZhFyPqnr4QEDMgF%2BR3XvLWMBWnOSF2lm77ts8hCAgMb%2BX43mWxQJaeuJYne9AS7mgPeNB8HyGvWCsFeqxTkVjPW2n1CvTK5outywjN0N62xfsWJGOJ67c3FXVOGS99QM8N7jrLrBKNuQRFWshot48w%3D%3D)\n",
        "\n",
        "## A Quick View into DQN\n",
        "\n",
        "The picture below will be the architecture of our Deep Q Learning. Our Deep Q Neural Network takes a stack of four frames as an input. These pass through its network, and output a vector of Q-values for each action possible in the given state. We need to take the biggest Q-value of this vector to find our best action.\n",
        "\n",
        "In the beginning, the agent does really badly. But over time, it begins to associate frames (states) with best actions to do.\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/dqn.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784374&Signature=BvkSaSeYYF7mewjUCEu2c4aLL7rI1GiX%2BZGMUtlzcKNjaJo6%2BWVYlXbJEBroP0H6WwXP8WAGiK5PKAELMfwHkRwI1mauItwfpqciISG99anrujXZK6%2FUPZeulTGk7Wn0oSUxeCRk3%2F1Mc4gbCjeSZE92L%2Fhgqdi71bidp2kwrhxbI9eFuefJ0lf5wEImmgsetChduJktg1WvCObcr66PZZIJcGWnYbRzuboHFxXkyXgmA0ZmzYs5UdQgMs23Bu219O2L%2Bee5PSu5QIVjN1A7Ni3f9en5pPYoOWOZzVXI%2BeM0pdHZ6LS9eN%2F%2FoYDGMWy2wa5ISrJMA1hl9A9RDm1XCQ%3D%3D)\n",
        "\n",
        "**paper**: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vBH92i1_GFNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "HczusvMUThk2"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2 as cv\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UoY1dP3_Thk5"
      },
      "cell_type": "markdown",
      "source": [
        "## OpenAI Gym and Atari Game\n",
        "\n",
        "https://github.com/openai/gym\n",
        "\n",
        "Gym is a toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Pinball.\n",
        "\n",
        "The Atari 2600 (or Atari Video Computer System or Atari VCS before November 1982) is a home video game console from Atari, Inc. Released on September 11, 1977.\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/ready_one.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784396&Signature=H4IsWaeuo%2BgQkO%2FFf1i039OmtQGmlsNgw91VshldUbBGqiH0QpUXSyEg6VFJMPURMlIsVQlNin4ukuhnmp0XFufDPGsF7Ov7r1ztfS2srVzrMOnc3PKfYg%2FtBTBdY83%2FoQ%2FRdimPle0VzRYxFWzF7VuBDcGPmYwfFsrkTPphPoKDMLOSuGJ92Jl%2Flk2n9qUDz1vdOudNUFO5E%2BwsyqSt8Efd3QcJVaLOzKzaiWxg4rokIids15Hw2j0Hz4MXnmb6JTGE8QXOAJq%2BGxAIZOGVQwqe%2BLWcmIo6XBEdLxTFQJht09BrVHqqnSKtJDpH8rTONSdmbSppwZYul5%2FoDJxtgw%3D%3D)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fb1kPTvEThk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "fc3b8b5e-297b-4c2f-a2a0-09bd0e76c0d7"
      },
      "cell_type": "code",
      "source": [
        "# for atari game support\n",
        "!pip install gym[atari]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (0.0.8)\n",
            "Collecting ale-py~=0.7.5 (from gym[atari])\n",
            "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[atari]) (6.4.0)\n",
            "Installing collected packages: ale-py\n",
            "Successfully installed ale-py-0.7.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              },
              "id": "5c3debdc28484a9795c1a960122d9e39"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfP2jBNxUT-f",
        "outputId": "0bd6d6f7-85b5-4700-ef48-bbfb2ba2def5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (0.0.8)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2 (from gym[accept-rom-license])\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (4.66.4)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2024.6.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446662 sha256=f4d1f094de3b697f6754f8678cc498bdf5459acf203baea60abd2dde4dfb0922\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Y2mwgoX6Thk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "986a69cf-225c-4d2a-ae98-ccf071da0e69"
      },
      "cell_type": "code",
      "source": [
        "import gym # Import the gym module\n",
        "import matplotlib.pyplot as plt # Import matplotlib\n",
        "\n",
        "env = gym.make('BreakoutDeterministic-v4')\n",
        "\n",
        "frame = env.reset()\n",
        "plt.figure() # Now plt is defined in this cell\n",
        "plt.imshow(frame)\n",
        "\n",
        "totalActions = env.action_space.n\n",
        "\n",
        "print(\"Shape = \",frame.shape)\n",
        "print(\"Action space size: Action  {}\".format(totalActions))\n",
        "print(env.unwrapped.get_action_meanings())\n",
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape =  (210, 160, 3)\n",
            "Action space size: Action  4\n",
            "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "YiZIllXQThk7"
      },
      "cell_type": "markdown",
      "source": [
        "## Frame Preprocessing\n",
        "\n",
        "Preprocessing is an important step. We want to reduce the complexity of our states to reduce the computation time needed for training.\n",
        "\n",
        "First, we can grayscale each of our states. Color does not add important information (in our case, we just need to find the enemy and kill him, and we don’t need color to find him). This is an important saving, since we reduce our three colors channels (RGB) to 1 (grayscale).\n",
        "\n",
        "Then we reduce the size of the frame, and we stack four sub-frames together. The stack operation will be done later in our code.\n",
        "\n",
        "Why use stack? -- Can you tell me where the ball is going if not use stack?\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/frame_pre.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784420&Signature=VlN%2FdN38dBvU8Xlf2A16Ghzdk2XPSeKSk6D%2BuyR6fPrJhIQoqPR9UoYAdb1D1dQ0Qo8hte2VQA%2FUnbf5LICL%2FfUfcgV7Syr4VE3zWJbmEUjYEq7zatijHXJKKYeK6aobdzNpOgjUqQefjbI5%2B%2Be4wzeUguKuQZ7MWdPG23hDbaAQrNlXk5s%2BxcUMYOVCk3NjAvXOOkXzE6HFXoDOeSxI7O2DAw2xP%2BOh3FP1xfb0IkQ4OTbplLo85b9uRZfnIXT8ZhYcbefYYKqrMeDIbv3VWBDES3tn2vc0%2B4W%2BnSvHU%2FBiB78dP71GlMSjH1UVH%2FZi2yhydeLNLpSmK2aN2inNhw%3D%3D)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IzKygxR-Thk8"
      },
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "    grayImg = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    resized = cv.resize(grayImg,(84,110))\n",
        "    preProcessedImg = resized[:84,:84]\n",
        "\n",
        "    return preProcessedImg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rGv0C7lMThk-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "70924767-46f2-4be2-b419-36fd9e885407"
      },
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "import cv2 # Import OpenCV\n",
        "import matplotlib.pyplot as plt # Import matplotlib\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "# Remove the first definition of preprocess\n",
        "\n",
        "def preprocess(img):\n",
        "    grayImg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # Use cv2 for OpenCV functions\n",
        "    resized = cv2.resize(grayImg,(84,110))\n",
        "    preProcessedImg = resized[:84,:84]\n",
        "\n",
        "    return preProcessedImg\n",
        "\n",
        "newFrame = preprocess(frame)\n",
        "print(newFrame.shape,newFrame.dtype)\n",
        "\n",
        "fig.add_subplot(1,3,1)\n",
        "plt.imshow(newFrame)\n",
        "\n",
        "fig.add_subplot(1,3,2)\n",
        "plt.imshow(frame)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "(84, 84) uint8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "keatSBADThlA"
      },
      "cell_type": "markdown",
      "source": [
        "## Using Convolution Networks\n",
        "\n",
        "The frames are processed by three convolution layers. These layers allow you to exploit spatial relationships in images. But also, because frames are stacked together, you can exploit some spatial properties across those frames.\n",
        "\n",
        "Each convolution layer will use RELU as an activation function. RELU has been proven to be a good activation function for convolution layers.\n",
        "\n",
        "We use one fully connected layer with RELU activation function and one output layer (a fully connected layer with a linear activation function) that produces the Q-value estimation for each action.\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/nature.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784442&Signature=HrYvJRejLdxXCwiig8OReZSuFpirObQM0xuTGXi7vZexi5DbGmz3ST15%2FfxGFvYrqNZQRCS45Z5NK%2BEhqo2PNWbJOg%2BKxnYRF%2BIl%2FyVNThHTs6VypDx5oHCC1B9wmgwpv5sRii60hvqbNHEK1sHdgdvTHePmHuJ8vTLBKxOTv1b1qM6%2B%2FT4xks9x98g5gfa8LXtqvrOt3tRQ1Ou2sT6sCyco3KDsQidRSTEn6JWsX2zhbsD0q6g4IidMxr4crv4hWszoXhOxzwK0BeqCdWUS9zkWSZjrFkXsJ3Hcovs0v%2FMigjs0Ce0JR85qJQ00wxMeWQAg1NO5Qjb6%2F2v4MxAxAg%3D%3D)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4fsv7ODIThlB"
      },
      "cell_type": "code",
      "source": [
        "class atariAgent():\n",
        "    \"\"\" Atari Agent contains the model and functions to predict and train the agent\"\"\"\n",
        "    def __init__(self,totalActions,scope = \"agent\"):\n",
        "        self.scope = scope\n",
        "        self.totalActions = totalActions\n",
        "        with tf.variable_scope(self.scope):\n",
        "            self.QModel()\n",
        "\n",
        "    def QModel(self):\n",
        "        \"\"\"Contains the model\"\"\"\n",
        "        self.Xin = tf.placeholder(shape=[None,84,84,4],dtype=tf.uint8,name='Xin')\n",
        "        self.y = tf.placeholder(shape=[None],dtype=tf.float32,name='yin')\n",
        "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32,name='actions')\n",
        "\n",
        "        X = tf.to_float(self.Xin) / 255.0 # scale to [0,1]\n",
        "\n",
        "        # model starts\n",
        "        conv1 = tf.contrib.layers.conv2d(X,16,8,4,activation_fn=tf.nn.relu)\n",
        "\n",
        "        conv2 = tf.contrib.layers.conv2d(conv1,32,4,2,activation_fn=tf.nn.relu)\n",
        "\n",
        "        convOut = tf.contrib.layers.flatten(conv2)\n",
        "        fc1 = tf.contrib.layers.fully_connected(convOut,256,activation_fn=tf.nn.relu)\n",
        "        self.QValues = tf.contrib.layers.fully_connected(fc1,self.totalActions,activation_fn=None)\n",
        "\n",
        "        batchSize = tf.shape(self.Xin)[0]\n",
        "        yIndices = tf.range(batchSize) * self.totalActions + self.actions\n",
        "        self.predictedActions = tf.gather(tf.reshape(self.QValues,[-1]),yIndices)\n",
        "\n",
        "        #c alculates loss function\n",
        "        self.losses = tf.squared_difference(self.y, self.predictedActions)\n",
        "        self.loss = tf.reduce_mean(self.losses)\n",
        "\n",
        "        # training step\n",
        "        self.optimizer = tf.train.RMSPropOptimizer(0.00025,0.99)\n",
        "        self.trainStep = self.optimizer.minimize(self.loss, global_step=tf.train.get_global_step())\n",
        "\n",
        "    def play(self,sess,states):\n",
        "        \"\"\"runs the model for the given state and predicts the Q values\"\"\"\n",
        "        return sess.run(self.QValues,{self.Xin : states})\n",
        "\n",
        "    def train(self,sess,states,y,actions):\n",
        "        \"\"\"Trains the Agent on the given input and target values and returns the loss\n",
        "        \"\"\"\n",
        "        feed_dict = { self.Xin: states, self.y: y, self.actions: actions }\n",
        "        loss, _ = sess.run([self.loss, self.trainStep],feed_dict)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1KpL_a2NThlC"
      },
      "cell_type": "markdown",
      "source": [
        "## Using Experience Replay\n",
        "\n",
        "Using experience replay can make more efficient use of observed experience. Experience replay will help us to handle two things:\n",
        "\n",
        "### Avoid forgetting previous experiences\n",
        "\n",
        "At each time step, we receive a tuple (state, action, reward, new_state). We learn from it (we feed the tuple in our neural network), and then throw this experience. Our problem is that we give sequential samples from interactions with the environment to our neural network. And it tends to forget the previous experiences as it overwrites with new experiences For instance, if we are in the first level and then the second (which is totally different), our agent can forget how to behave in the first level.\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/mario.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784462&Signature=spqD7dfEr2vushuVudWg0A%2FXvJ3x%2BQTLASLh9aGH3ngqnmqkuVM9vChG%2FZSH3YOlf0OCFmr2hoTMP44C%2FYrc164UtGOR2AKjvHs%2FDFUhuSWsOgtKR6bbknc2kcV%2FaySP56ZSReBeB%2B4EsMEE0DuD33g3T7kDdB9%2FI%2B0GydChszkfrBM8EvQvfHr6VncZpRABfls2oTNvxyMcd98%2Bydiy4jyFubvTzxb8BVjW64XlVKM0SYoIhxXyHx7suYIU9UsBf76PecbexwZaMtcNhNOsuwsJel6FUEpNkgutYnvpyfJ8Sw1L6CYLKk37%2FilK69PR4NXAqGdOSMD%2Fa54Uo1F4yQ%3D%3D)\n",
        "\n",
        "Our solution: create a “replay buffer.” This stores experience tuples while interacting with the environment, and then we sample a small batch of tuple to feed our neural network. As a consequence, it can be more efficient to make use of previous experience, by learning with it multiple times.\n",
        "\n",
        "Think of the replay buffer as a folder where every sheet is an experience tuple. You feed it by interacting with the environment. And then you take some random sheet to feed the neural network. This prevents the network from only learning about what it has immediately done.\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/erb.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784480&Signature=pC5Cvc6abVZwfK3ENYogFFKhRvFuWNbmZftX7bDYEmURWLJ5hH6oUVugnaGlVCTJMiS8wS7frRwJQeyuZstkFze8fyN0f1vXVbXd5KVQibvcpVQK1tHaTBe3AGJly9C2PesC3OmRmWAAdxMmIYNh4lc4v8ZvcOshH3bp4HfVUTfEMKbb1tGqFFPWngLCJFYgb0RZUR0biH%2FQhoITNdSMAKIep58oiup0dSgxPygjysgVsAqrDWrVufL46fKbR8Rlr4mGMKNvZw0z%2BEkIJb4UtGiWdU2Wv67S%2FDIbEZ4k6k2YexO1jsKl%2Bt52gdUG2fJFTWqrpZ%2BMLdez%2Fsfn7aGcUA%3D%3D)\n",
        "\n",
        "### Reduce correlations between experiences\n",
        "\n",
        "We have another problem — we know that every action affects the next state. This outputs a sequence of experience tuples which can be highly correlated. If we train the network in sequential order, we risk our agent being influenced by the effect of this correlation.\n",
        "\n",
        "By sampling from the replay buffer at random, we can break this correlation. This prevents action values from oscillating or diverging catastrophically."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "K5hVO8xEThlC"
      },
      "cell_type": "code",
      "source": [
        "from collections import namedtuple,deque\n",
        "\n",
        "def initExperienceReplay(env, initReplaySize: int, cell: namedtuple):\n",
        "    replayBuffer = deque()\n",
        "    state = env.reset()\n",
        "    state = preprocess(state)\n",
        "    state = np.stack([state]*4,axis=2)\n",
        "    print(\"Filling Experience memory of the agent\")\n",
        "    for i in range(initReplaySize):\n",
        "        action = env.action_space.sample()\n",
        "        nextState, reward, isDone, _ = env.step(action)\n",
        "        nextState = preprocess(nextState)\n",
        "        nextState = np.append(state[:,:,1:],nextState[:,:,np.newaxis],axis=2)\n",
        "        replayBuffer.append(cell(state,reward,action,nextState,isDone))\n",
        "        if(isDone):\n",
        "            state = env.reset()\n",
        "            state = preprocess(state)\n",
        "            state = np.stack([state]*4,axis=2)\n",
        "        else:\n",
        "            state = nextState\n",
        "\n",
        "    env.close()\n",
        "    print(\"Filled memory of size {}\".format(len(replayBuffer)))\n",
        "    return replayBuffer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3mFg0U4KThlD"
      },
      "cell_type": "markdown",
      "source": [
        "## Using Separate Target Network\n",
        "\n",
        "The third major addition to the DQN that makes it unique is the utilization of a second network during the training procedure. This second network is used to generate the target-Q values that will be used to compute the loss for every action during training.\n",
        "\n",
        "### Why not use just use one network for both estimations?\n",
        "\n",
        "The issue is that at every step of training, the Q-network’s values shift, and if we are using a constantly shifting set of values to adjust our network values, then the value estimations can easily spiral out of control. The network can become destabilized by falling into feedback loops between the target and estimated Q-values. In order to mitigate that risk, the target network’s weights are fixed, and only periodically or slowly updated to the primary Q-networks values. In this way training can proceed in a more stable manner."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Jq83_lYkThlD"
      },
      "cell_type": "code",
      "source": [
        "def copyParameters(sess,targetModel,QModel):\n",
        "    params1 = [var for var in tf.trainable_variables() if var.name.startswith(targetModel.scope)]\n",
        "    params1 = sorted(params1,key=lambda var: var.name)\n",
        "    params2 = [var for var in tf.trainable_variables() if var.name.startswith(QModel.scope)]\n",
        "    params2 = sorted(params2,key=lambda var: var.name)\n",
        "    copies = []\n",
        "    for p1,p2 in zip(params1,params2):\n",
        "        copy = p1.assign(p2)\n",
        "        copies.append(copy)\n",
        "    sess.run(copies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDyUbmbuThlD"
      },
      "cell_type": "markdown",
      "source": [
        "## Action Selection\n",
        "\n",
        "Still simply using the $\\epsilon$-greedy policy."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HHFAccXAThlE"
      },
      "cell_type": "code",
      "source": [
        "def EGreedyPolicy(epsilon,QValues):\n",
        "    numActions = QValues.shape[1]\n",
        "    probs = np.ones(numActions, dtype=float) * epsilon / numActions\n",
        "    best_action = np.argmax(QValues)\n",
        "\n",
        "    probs[best_action] += (1.0 - epsilon)\n",
        "\n",
        "    optimizedAction = np.random.choice(numActions,p=probs)\n",
        "    return optimizedAction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YXAbwmLEThlE"
      },
      "cell_type": "markdown",
      "source": [
        "## Train It\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/374075/727251/update.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570784518&Signature=D0DXdzE7YyS6kkI1dbSL2zPE43%2Fl%2B4MYqpaKSth3Gss2QC6D7qENLtvEi5zUN3c0ZnSg2EqCNSJgP0d766vwRFZrTr2xYlou5%2Bv03UN86LEHiCqSp2ksRLYy2aMX%2FrpWg7dHjPDfnmkkmQcTKCObnr7No6eORyqbdriPfUMGBBCmeQtZQvUltOzvP%2Fs1VuiBo4G3riJwMgbG7LDuFvxnzPKBvQxQCczOLEtHK6n3NTHolib71crBTGkrPWHwZLWj%2BpkavDBGJzM2OBWokZwBlvhuGqRsbzs8lEK2pZbWOKZtPqeuRIUmRWPG1N0Ezw4NV4bzkIIt4eHPWqOkJ0pE%2Bw%3D%3D)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fTFjapbqThlE"
      },
      "cell_type": "code",
      "source": [
        "numEpisodes = 5  # determines the number of episode\n",
        "initReplaySize = 5000\n",
        "replaySize = 10000\n",
        "batchSize = 32\n",
        "startE = 1.0  # for epsilon decay, start from 1.0\n",
        "endE = 0.1  # for epsilon decay, end with 0.1\n",
        "annealingSteps = 5000  # for epsilon decay, determines the decay step\n",
        "copyFrequency = 10000  # determines the update frequency\n",
        "videoFrequency = 5000\n",
        "discountFactor = 0.99  # discounted factor\n",
        "checkpointDir = \"checkpoint\"\n",
        "monitorDir = \"monitor\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_IV0jHtIThlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1ffcdb-d2af-46e1-ea6e-5bfc7eb4f2b2"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym[classic_control]\n",
        "import gym\n",
        "from gym import wrappers  # Import wrappers from gym directly\n",
        "\n",
        "def trainAgent():\n",
        "    #start environment\n",
        "    env = gym.make('BreakoutDeterministic-v4')\n",
        "\n",
        "    totalActions = env.action_space.n\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    # initialize target and evaluation model\n",
        "    targetModel = atariAgent(totalActions,scope=\"targetModel\")\n",
        "    QModel = atariAgent(totalActions,scope=\"QModel\")\n",
        "\n",
        "    if not os.path.exists(checkpointDir):\n",
        "        os.makedirs(checkpointDir)\n",
        "    if not os.path.exists(monitorDir):\n",
        "        os.makedirs(monitorDir)\n",
        "\n",
        "    checkpoint = os.path.join(checkpointDir,\"model\")\n",
        "    monitor = os.path.join(monitorDir,\"game\")\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        saver = tf.train.Saver()\n",
        "\n",
        "        # Use wrappers.Monitor instead of gym.wrappers.Monitor\n",
        "        env = wrappers.Monitor(env, directory=monitor, video_callable=lambda totalStep: totalStep % \\\n",
        "                      videoFrequency==0, resume=True)\n",
        "\n",
        "        state = env.reset()\n",
        "\n",
        "        # ... rest of your code ...\n",
        "\n",
        "        ckpt = tf.train.latest_checkpoint(checkpointDir)\n",
        "        if ckpt:\n",
        "            saver.restore(sess,ckpt)\n",
        "            totalStep = 0\n",
        "            print(\"Existing checkpoint {} restored...\".format(ckpt))\n",
        "        else:\n",
        "            totalStep = 0\n",
        "\n",
        "        cell = namedtuple(\"cell\",\"state reward action nextState isDone\")\n",
        "\n",
        "        replayMemory = initExperienceReplay(env,initReplaySize,cell)\n",
        "\n",
        "        epsilonValues = np.linspace(startE,endE,num=annealingSteps)\n",
        "\n",
        "        episodeLengths = []\n",
        "        episodeRewards = []\n",
        "\n",
        "        print(\"\\n---------- Main Loop ----------\")\n",
        "\n",
        "        for episode in range(numEpisodes):\n",
        "            state = env.reset()\n",
        "            state = preprocess(state)\n",
        "            state = np.stack([state] * 4, axis=2)\n",
        "\n",
        "            loss = None\n",
        "            episodeLength = 0\n",
        "            totalReward = 0.\n",
        "\n",
        "            while(True):\n",
        "                if(totalStep%copyFrequency == 0):\n",
        "                    copyParameters(sess,targetModel,QModel)\n",
        "                    print(\"\\nTarget Model updated...\")\n",
        "\n",
        "                epsilon = epsilonValues[min(totalStep, annealingSteps-1)]\n",
        "                QValues = QModel.play(sess,np.expand_dims(state,0))\n",
        "                bestAction = EGreedyPolicy(epsilon,QValues)\n",
        "\n",
        "                nextState,reward,isDone,_ = env.step(bestAction)\n",
        "                nextState = preprocess(nextState)\n",
        "                nextState = np.append(state[:,:,1:],nextState[:,:,np.newaxis],axis=2)\n",
        "\n",
        "                totalReward += reward\n",
        "\n",
        "                if(len(replayMemory) == replaySize):\n",
        "                    replayMemory.popleft()\n",
        "\n",
        "                replayMemory.append(cell(state,reward,bestAction,nextState,isDone))\n",
        "\n",
        "                indices = np.random.choice(len(replayMemory)-1,batchSize,replace=False)\n",
        "                batch = [replayMemory[i] for i in indices]\n",
        "                states,rewards,actions,nextStates,isDones = map(np.array,zip(*batch))\n",
        "\n",
        "                # targetmodel prediction\n",
        "                tQValues = targetModel.play(sess,nextStates)\n",
        "                targetY = rewards + (1 - isDones) * discountFactor * np.amax(tQValues,axis=1)\n",
        "\n",
        "                # gradient descent step\n",
        "                loss = QModel.train(sess,states,targetY,actions)\n",
        "                episodeLength += 1\n",
        "                totalStep += 1\n",
        "\n",
        "                if(isDone):\n",
        "                    episodeRewards.append(reward)\n",
        "                    episodeLengths.append(episodeLength)\n",
        "                    print(\"\\r[Episode {}]\\tGlobal step: {} Final reward: {} Total reward: {} episode length: {} loss: {}\"\\\n",
        "                          .format(episode,totalStep,reward,totalReward,episodeLength,loss), end=\"\", flush=True)\n",
        "\n",
        "                    saver.save(tf.get_default_session(), checkpoint)\n",
        "                    break\n",
        "\n",
        "                else:\n",
        "                    state = nextState\n",
        "                    totalStep += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (0.0.8)\n",
            "Collecting pygame==2.1.0 (from gym[classic_control])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.0\n",
            "    Uninstalling pygame-2.6.0:\n",
            "      Successfully uninstalled pygame-2.6.0\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zFv7kVo3ThlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a752fb5-bb1a-46bc-f8a7-65975d354566"
      },
      "cell_type": "code",
      "source": [
        "# ready for training\n",
        "!apt install -y ffmpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15 # Install TF 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "def trainAgent():\n",
        "    #start environment\n",
        "    env = gym.make('BreakoutDeterministic-v4')\n",
        "\n",
        "    totalActions = env.action_space.n\n",
        "\n",
        "    tf.reset_default_graph() # Reset the default graph in TF 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlhtcqwOYsjC",
        "outputId": "e2a5e7a5-8b7b-4f6c-b0d8-66869ef3c1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.15\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0pzbEBowThlG"
      },
      "cell_type": "markdown",
      "source": [
        "## Google's Video\n",
        "\n",
        "Google DeepMind's Deep Q-learning playing Atari Breakout\n",
        "\n",
        "https://www.youtube.com/watch?v=V1eYniJ0Rnk"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}